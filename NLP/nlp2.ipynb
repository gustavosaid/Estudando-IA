{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feecda47",
   "metadata": {},
   "source": [
    "#### Configuração do ambiente\n",
    "\n",
    "Crie o ambiente virtual python:\n",
    "\n",
    "```bash\n",
    "python3 -m venv venv\n",
    "```\n",
    "\n",
    "Ative o ambiente:\n",
    "\n",
    "```bash\n",
    "source venv/bin/activate\n",
    "```\n",
    "\n",
    "Instale as dependências:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements_nlp.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f35e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8189ef43",
   "metadata": {},
   "source": [
    "### Representação textual\n",
    "\n",
    "##### Tokenizando com huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97697a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/ml-supervised-dev/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Tokenizador do huggingface\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd1e0f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 15:02:35.879311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1757257359.100295    2191 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1757257359.928226    2191 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1757257366.936002    2191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757257366.936043    2191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757257366.936045    2191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1757257366.936047    2191 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-07 15:02:47.399929: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Modelo baseado em português - BERTimbau\n",
    "# É um modelo pré-treinado (com pesos ajustados) para a língua portuguesa\n",
    "# Serve de interface (arquitetura pré-definida) para ser executado por algum \"backend\" e obter os embeddings\n",
    "nome_modelo = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(nome_modelo)\n",
    "model = AutoModel.from_pretrained(nome_modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6ca2618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['[CLS]', 'Ara', '##gor', '##n', 'se', 'juntou', 'aos', 'ho', '##bb', '##its', '[SEP]']\n",
      "IDs: [101, 3079, 5967, 22285, 176, 6440, 712, 588, 14944, 4426, 102]\n"
     ]
    }
   ],
   "source": [
    "texto = \"Aragorn se juntou aos hobbits\"\n",
    "tokens = tokenizer(texto, return_tensors=\"pt\")\n",
    "print(\"Tokens:\", tokenizer.convert_ids_to_tokens(tokens[\"input_ids\"][0]))\n",
    "print(\"IDs:\", tokens[\"input_ids\"][0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "273ee4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape dos embeddings: torch.Size([1, 11, 768])\n",
      "\n",
      "Embedding do [CLS] (primeiros 10 valores): tensor([ 0.1166, -0.0959,  0.7519, -0.1015,  0.1374,  0.1467,  0.1436, -0.0992,\n",
      "        -0.1259,  0.2872])\n",
      "\n",
      "Embedding do token 'hobbits' (primeiros 10 valores): tensor([ 0.0729, -0.3708,  0.9874, -0.1687,  0.0560, -0.3307,  0.3781, -0.6053,\n",
      "         0.1463, -0.9487])\n"
     ]
    }
   ],
   "source": [
    "# O pytorch é usado como backend para executar nosso modelo pré-treinado BERTimbau\n",
    "# Gera embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokens)\n",
    "    embeddings = outputs.last_hidden_state  # [batch, seq_len, hidden_dim]\n",
    "\n",
    "print(\"\\nShape dos embeddings:\", embeddings.shape)\n",
    "\n",
    "# Exibe o embedding do primeiro token (CLS) e do token 'hobbits'\n",
    "cls_embedding = embeddings[0][0]\n",
    "hobbits_embedding = embeddings[0][-2]\n",
    "\n",
    "print(\"\\nEmbedding do [CLS] (primeiros 10 valores):\", cls_embedding[:10])\n",
    "print(\"\\nEmbedding do token 'hobbits' (primeiros 10 valores):\", hobbits_embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d07607",
   "metadata": {},
   "source": [
    "#### Visualizando como os embeddings capturam o contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e687c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade entre 'banco' (diferentes contextos): 0.6787\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Aqui temos duas frases em contextos bem diferentes.\n",
    "Veja que a similaridade entre os vetores \"banco\" é pequena\n",
    "'''\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Frases para contexto\n",
    "texto1 = \"Eu sentei no banco da praça para descançar\"\n",
    "texto2 = \"Eu fui ao banco abrir uma conta corrente\"\n",
    "\n",
    "# Tokenização\n",
    "tokens1 = tokenizer(texto1, return_tensors=\"pt\")\n",
    "tokens2 = tokenizer(texto2, return_tensors=\"pt\")\n",
    "\n",
    "# Obtendo embeddings\n",
    "with torch.no_grad():\n",
    "    emb1 = model(**tokens1).last_hidden_state\n",
    "    emb2 = model(**tokens2).last_hidden_state\n",
    "\n",
    "# Obtendo o índice do token 'banco'\n",
    "idx1 = tokens1['input_ids'][100].tolist().index(tokenizer.convert_tokens_to_ids('banco'))\n",
    "idx2 = tokens2['input_ids'][100].tolist().index(tokenizer.convert_tokens_to_ids('banco'))\n",
    "\n",
    "vec1 = emb1[0][idx1]\n",
    "vec2 = emb2[0][idx2]\n",
    "\n",
    "# Similaridade de cosseno\n",
    "similaridade = F.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(100))\n",
    "print(f\"Similaridade entre 'banco' (diferentes contextos): {similaridade.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b401473d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade entre 'banco' (diferentes contextos): 0.8695\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Já nesse exemplo o vetor de \"banco\" deve ser mais similar, já que o contexto é parecido\n",
    "'''\n",
    "\n",
    "# Frases para contexto\n",
    "texto1 = \"O banco tinha opção de conta universitária\"\n",
    "texto2 = \"Eu fui ao banco abrir uma conta corrente\"\n",
    "\n",
    "# Tokenização\n",
    "tokens1 = tokenizer(texto1, return_tensors=\"pt\")\n",
    "tokens2 = tokenizer(texto2, return_tensors=\"pt\")\n",
    "\n",
    "# Obtendo embeddings (last_hidden_state)\n",
    "with torch.no_grad():\n",
    "    emb1 = model(**tokens1).last_hidden_state\n",
    "    emb2 = model(**tokens2).last_hidden_state\n",
    "\n",
    "# Obtendo o índice do token 'banco'\n",
    "idx1 = tokens1['input_ids'][0].tolist().index(tokenizer.convert_tokens_to_ids('banco'))\n",
    "idx2 = tokens2['input_ids'][0].tolist().index(tokenizer.convert_tokens_to_ids('banco'))\n",
    "\n",
    "vec1 = emb1[0][idx1]\n",
    "vec2 = emb2[0][idx2]\n",
    "\n",
    "# Similaridade de cosseno\n",
    "# Unsqueeze para adicionar uma dimensão a mais na posição 0\n",
    "similaridade = F.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(0))\n",
    "print(f\"Similaridade entre 'banco' (diferentes contextos): {similaridade.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d80416",
   "metadata": {},
   "source": [
    "#### Observações importantes\n",
    "\n",
    "Usamos um modelo de rede neural pré-treinado (BERTimbau) para obter os vetores. Esse é um modelo baseado na arquitetura Transformers+Attention. Mas um detalhe é importante entender nessa tarefa de obter os embeddings: o \"last_hidden_state\".\n",
    "\n",
    "O \"last_hidden_state\" é uma propriedade que nos retorna a última camada escondida da rede neural. Portanto, aqui não estamos preocupados com a camada de saída. Mas porque a é usado a última camada? Porque queremos um **vetor** que represente a palavra, e a saída da última camada escondida é um vetor com valores que foram obtidos após o processo de treinamento dessa rede, e portanto podemos interpretar o mesmo como sendo uma representação numérica da palavra.\n",
    "\n",
    "É importante também entender como a arquitetura Transformers+Attention funciona, o que será feito nas próximas aulas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
